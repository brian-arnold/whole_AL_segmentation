{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results_tmp'\n",
    "import os\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_info import samples, data_dir, puffs, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data directory: /mnt/cup/labs/mcbride/bjarnold/new_analysis/data/Mar_22_2024/1_RegisteredBrains\n",
      "Number of samples: 15\n",
      "Number of odors: 72\n",
      "x,y,z dimensions: 128 128 24\n",
      "Number of frames to analyze: 112\n",
      "Number of initial frames for df/f normalization: 20\n"
     ]
    }
   ],
   "source": [
    "# import custom functions\n",
    "import functions as fn\n",
    "\n",
    "print(f'data directory: {data_dir}')\n",
    "print(f'Number of samples: {len(samples)}')\n",
    "num_odors = len(puffs)\n",
    "\n",
    "print(f'Number of odors: {num_odors}')\n",
    "print(f'x,y,z dimensions:', params['x_dim'], params['y_dim'], params['z_dim'])\n",
    "print(f'Number of frames to analyze:', params['n_frames_to_analyze'])\n",
    "print(f'Number of initial frames for df/f normalization:', params['background_frames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# These functions take in mean activity traces and output summary statistics or modified traces\n",
    "######\n",
    "\n",
    "def max_activity_per_odor(mean_activity, puffs, n_frames_to_analyze):\n",
    "\n",
    "    maxs_per_odor = defaultdict(list)\n",
    "    argmaxs_per_odor = defaultdict(list) # this is to find the frame with maximum activity\n",
    "    \n",
    "    for i,puff in enumerate(puffs):\n",
    "        odor_name = puff.odor_name\n",
    "        # since a subset of videos were concatenates, use index i of odor_of_interest_indices to get the corresponding interval\n",
    "        interval = mean_activity[i*n_frames_to_analyze : (i+1)*n_frames_to_analyze]\n",
    "\n",
    "        maxs_per_odor[odor_name].append(np.max(interval))\n",
    "        argmaxs_per_odor[odor_name].append(np.argmax(interval))\n",
    "\n",
    "    for odor in maxs_per_odor:\n",
    "        assert len(maxs_per_odor[odor]) <= 2, f\" for odor {odor} there were more than 2 trials. This is unexpected.\"\n",
    "        assert len(argmaxs_per_odor[odor]) <= 2, f\" for odor {odor} there were more than 2 trials. This is unexpected.\"\n",
    "\n",
    "    return maxs_per_odor, argmaxs_per_odor\n",
    "\n",
    "def activity_auc_per_odor(mean_activity, puffs, n_frames_to_analyze, background_frames):\n",
    "\n",
    "    aucs_per_odor = defaultdict(list)\n",
    "    # for each odor, extract max value from the corresponding interval\n",
    "    for i, puff in enumerate(puffs):\n",
    "        # get odor name\n",
    "        odor_name = puff.odor_name\n",
    "\n",
    "        # since a subset of videos were concatenates, use index i of odor_of_interest_indices to get the corresponding interval\n",
    "        interval = mean_activity[i*n_frames_to_analyze : (i+1)*n_frames_to_analyze]\n",
    "\n",
    "        # baseline= 1.96*np.std(interval[0:background_frames])\n",
    "        baseline= np.median(interval[0:background_frames])\n",
    "        peak_coord = np.argmax(interval)\n",
    "\n",
    "        # get all indices of interval where activity is above baseline\n",
    "        above_baseline = np.where(interval > baseline)[0]\n",
    "        # find sets of indices in above_baseline that are consecutive, if not consecutive, then activity dropped below baseline\n",
    "        not_consecutive = np.where(np.diff(above_baseline) != 1)[0]\n",
    "        # an extra 1 is added to account for fact that np.diff returns array that is 1 element shorter than the input array, so add 1 to split at correct indices\n",
    "        split_indices = np.split(above_baseline, not_consecutive+1)\n",
    "\n",
    "        # find interal that contains the peak index\n",
    "        for s in split_indices:\n",
    "            if peak_coord in s:\n",
    "                start = s[0]  # indices are for where activity is above baseline, so start 1 before\n",
    "                end = s[-1] + 1 # indices are for where activity is above baseline, so end 1 after, and add extra 1 to include the last index\n",
    "                peak_interval = interval[start:end]\n",
    "                break\n",
    "\n",
    "        # calculate area under the curve\n",
    "        auc = np.trapz(peak_interval, dx=1)\n",
    "        aucs_per_odor[odor_name].append(auc)\n",
    "\n",
    "        # if test and i == 4 and self.name == list(activity_traces.keys())[0]:\n",
    "        #     plt.plot(interval)\n",
    "        #     plt.axhline(baseline, color='black', linestyle='--')\n",
    "        #     plt.axvline(peak_coord, color='red')\n",
    "        #     plt.axvline(start, color='green')\n",
    "        #     plt.axvline(end, color='green')\n",
    "        #     print(auc)\n",
    "\n",
    "        for odor in aucs_per_odor:\n",
    "            assert len(aucs_per_odor[odor]) <= 2, f\" for odor {odor} there were more than 2 trials. This is unexpected.\"\n",
    "\n",
    "        return aucs_per_odor\n",
    "    \n",
    "def subtract_paraffin_response(mean_activity, puffs, n_frames_to_analyze):\n",
    "\n",
    "    num_odors = len(puffs)\n",
    "\n",
    "    # find indices of the odors delivered that correspond to paraffin, should be 2 for 2 trials\n",
    "    paraffin_indices = [p.number for p in puffs if p.odor_name == \"paraffin\"]\n",
    "    assert len(paraffin_indices) == 2, f\"Expected to find 2 paraffin trials, but found {len(paraffin_indices)}\"\n",
    "    assert paraffin_indices[0] < paraffin_indices[1], f\"Expected paraffin trial 1 to come before paraffin trial 2, but found {paraffin_indices}\"\n",
    "\n",
    "    new_traces = []\n",
    "    # collect paraffin traces for this sample, for both trials; in paraffin_traces dict, keys are trials\n",
    "    paraffin_traces = {}\n",
    "    for i, index in enumerate(paraffin_indices):\n",
    "        interval = mean_activity[index*n_frames_to_analyze:(index+1)*n_frames_to_analyze]\n",
    "        paraffin_traces[i] = interval\n",
    "    \n",
    "    # subtract paraffin traces from each odor trace\n",
    "    for puff in puffs:\n",
    "        i = puff.number\n",
    "        interval = mean_activity[i*n_frames_to_analyze:(i+1)*n_frames_to_analyze]\n",
    "        # if this odor was delivered in the first half, subtract paraffin trace from first trial\n",
    "        if i <= (num_odors/2) - 1:\n",
    "            interval_subtracted = interval - paraffin_traces[0]\n",
    "        else:\n",
    "            interval_subtracted = interval - paraffin_traces[1]\n",
    "        new_traces.extend(interval_subtracted)\n",
    "\n",
    "    mean_activity_paraffin_subtracted = np.array(new_traces)\n",
    "    return mean_activity_paraffin_subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski\n",
    "import numpy as np\n",
    "import caiman as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "class Brain:\n",
    "\n",
    "    # This class stores data and preprocessing methods\n",
    "    #\n",
    "    # name: name of the sample\n",
    "    # vid_fnames: the file paths of all the individual videos\n",
    "    # video: the full video, a concatenation of all individual videos\n",
    "    # binary_mask: 3D outline of the antennal lobe, region in video of higher pixel intensities according to otsu thresholding\n",
    "    # binary_mask_frac: the fraction of pixels contained within binary_mask, compared to the entire 3d volume\n",
    "    # mean_activity: the mean pixel intensity wtihin binary mask, over time; this is df_f if videos have been normalized against background activity\n",
    "    # mean_activity_paraffin_subtracted: same as mean_activity except the signal of the paraffin odor has been subtracted\n",
    "    # maxs_per_odor: a dictionary where keys are names of odors, values are lists of size 2, one for each trial in which the odor was administered\n",
    "    # aucs_per_odor: same as maxs_per_odor, except calculating the area under the curve\n",
    "\n",
    "    def __init__(self, name, vid_fnames):\n",
    "        self.name = name\n",
    "        self.vid_fnames = vid_fnames\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Brain for {self.name} containing {len(self.vid_fnames)} videos\"\n",
    "    \n",
    "    def reshape_vid(self, V, x_dim, y_dim, z_dim):\n",
    "        # reshapes a video matrix into 4 dimensions: (n_frames, x, y, z)\n",
    "        try:\n",
    "            # 1st dimension of Y is time X z_stacks, so reshape according to specified z_stacks\n",
    "            V_reshaped = np.reshape(V, (int(V.shape[0]/z_dim), z_dim, x_dim, y_dim))\n",
    "        except ValueError:\n",
    "            print(f\"V.shape: {V.shape}, x_dim: {x_dim}, y_dim: {y_dim}, z_dim: {z_dim}\")\n",
    "            raise ValueError(\"The dimensions of the video are not compatible with the specified x,y,z dimensions. Please check the dimensions of the video and the x,y,z dimensions specified in experiment_info.py\")\n",
    "        # transpose to (n_frames, x, y, z)\n",
    "        V_reshaped2 = np.transpose(V_reshaped, (0, 2, 3, 1))\n",
    "        return V_reshaped2\n",
    "\n",
    "    def background_normalize(self, V, background_frames, offset=1000):\n",
    "        # normalize pixel intensity according to the mean of the first background_frames\n",
    "        # the default of offset=1000 was taken from Martin's code!\n",
    "        # V has shape (frames, x,y,z), first `background_frames` frames are background\n",
    "        V = V + offset\n",
    "        background = np.mean(V[0:background_frames,:,:,:], axis=0) # get mean of each pixel for 1st 20 frames\n",
    "        V_normalized = (V - background)/(background+0.0000000000000000000001) # subtract and divide by background\n",
    "        return V_normalized\n",
    "\n",
    "    def load_videos(self, params, normalize=False):\n",
    "        # takes video file names in vid_fnames and loads them into list of CaImAn movie objects\n",
    "        x_dim, y_dim, z_dim = params['x_dim'], params['y_dim'], params['z_dim']\n",
    "        n_frames_to_analyze = params['n_frames_to_analyze']\n",
    "        background_frames = params['background_frames']\n",
    "        \n",
    "        vid_list = []\n",
    "        for v_fname in self.vid_fnames:\n",
    "            V = cm.load(v_fname)\n",
    "            V = self.reshape_vid(V, x_dim, y_dim, z_dim)\n",
    "            assert V.shape[0] >= n_frames_to_analyze, f\"Number of frames in video is less than n_frames_to_analyze. Please specify a smaller number of frames to analyze.\"\n",
    "            # only analyze first 'n_frames_to_analyze' frames\n",
    "            V = V[:n_frames_to_analyze] \n",
    "            if normalize:\n",
    "                V = self.background_normalize(V, background_frames)\n",
    "            vid_list.append(V)\n",
    "            \n",
    "        self.video = cm.concatenate(vid_list)\n",
    "\n",
    "    def find_binary_mask(self, params, results_dir):\n",
    "        # uses scikit image to find binary mask from movie object\n",
    "        x_dim, y_dim, z_dim = params['x_dim'], params['y_dim'], params['z_dim']\n",
    "        # create single volume by taking the mean across frames\n",
    "        V_smoothed = np.mean(self.video, axis=0)\n",
    "        # spatial smoothing, median filter across pixels\n",
    "        V_smoothed = ski.filters.median(V_smoothed, behavior='ndimage')\n",
    "        # thresholding\n",
    "        thresh = ski.filters.threshold_otsu(V_smoothed)\n",
    "\n",
    "        self.binary_mask = V_smoothed > thresh \n",
    "        self.binary_mask_frac = np.sum(self.binary_mask)/(x_dim*y_dim*z_dim)\n",
    "\n",
    "        self.save_and_plot_binary_mask(params, results_dir)\n",
    "    \n",
    "    def save_and_plot_binary_mask(self, params, results_dir):\n",
    "     \n",
    "        mask_dir = f'{results_dir}/binary_masks'\n",
    "        plot_dir = f'{results_dir}/binary_mask_plots'\n",
    "\n",
    "        os.makedirs(mask_dir, exist_ok=True)\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "        # save binary mask\n",
    "        with open(f'{mask_dir}/{self.name}.pkl', 'wb') as f:\n",
    "            pickle.dump(self.binary_mask, f)\n",
    "\n",
    "        # plot binary masks\n",
    "        colors = [(0, 0, 0, 0), (0, 0, 0, 0.1)]  # RGBA tuples, the 1st color's alpha set to 0 to make transparent so white values are ignores, black values are partially transparent; 0's mapped to 1st color, 1's mapped to 2nd color\n",
    "        cmap = ListedColormap(colors)\n",
    "\n",
    "        fig, ax = plt.subplots(1,1, figsize=(3,3))\n",
    "        for i in range(0, params['z_dim']):\n",
    "            plt.imshow(self.binary_mask[:,:,i], cmap=cmap)\n",
    "        plt.title(self.name)\n",
    "        sns.despine()\n",
    "        plt.savefig(f'{plot_dir}/{self.name}.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def mean_activity_within_binary_mask(self, params):\n",
    "        # using pixels contained in binary_mask, measure the mean pixel intensity over time\n",
    "\n",
    "        x_dim, y_dim, z_dim = params['x_dim'], params['y_dim'], params['z_dim']\n",
    "        # vectorize both the binary mask and the video\n",
    "        binary_mask_reshaped = np.reshape(self.binary_mask, (x_dim*y_dim*z_dim))\n",
    "        video_reshaped = np.reshape(self.video, (self.video.shape[0], -1))\n",
    "        video_reshaped = np.array(video_reshaped)\n",
    "        print(binary_mask_reshaped.shape, video_reshaped.shape)\n",
    "\n",
    "        self.mean_activity = np.mean(video_reshaped[:,binary_mask_reshaped], axis=1)\n",
    "\n",
    "    def subtract_paraffin(self, puffs, params):\n",
    "        \n",
    "        n_frames_to_analyze = params['n_frames_to_analyze']\n",
    "        self.mean_activity_paraffin_subtracted = subtract_paraffin_response(self.mean_activity, puffs, n_frames_to_analyze)\n",
    "\n",
    "    def compute_max_responses(self, puffs, params):\n",
    "        # this is a wrapper function for 'max_activity_per_odor' which can also be used on paraffin subtracted activity\n",
    "\n",
    "        n_frames_to_analyze = params['n_frames_to_analyze']\n",
    "        maxs_per_odor, argmaxs_per_odor = max_activity_per_odor(self.mean_activity, puffs, n_frames_to_analyze)\n",
    "\n",
    "        self.maxs_per_odor = maxs_per_odor\n",
    "        self.argmaxs_per_odor = argmaxs_per_odor\n",
    "\n",
    "    def compute_AUC(self, puffs, params, test=False):\n",
    "        n_frames_to_analyze = params['n_frames_to_analyze']\n",
    "        background_frames = params['background_frames']\n",
    "\n",
    "        aucs_per_odor = activity_auc_per_odor(self.mean_activity, puffs, n_frames_to_analyze, background_frames)\n",
    "\n",
    "        self.aucs_per_odor = aucs_per_odor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the brains list will store instances of the Brain class that will keep track of data and preprocessing methods\n",
    "brains = []\n",
    "\n",
    "for samp in samples:\n",
    "    v = glob.glob(f\"{data_dir}/{samp}/*.registered.tif\")\n",
    "    v = sorted(v)\n",
    "    num_vids = len(v)\n",
    "    assert num_vids == len(puffs), f\"I found {num_vids} videos for sample {samp}, but there are {len(puffs)} odors. The number of videos and odors should be equivalent.\"\n",
    "    \n",
    "    brain = Brain(samp, v)\n",
    "    brains.append(brain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393216,) (8064, 393216)\n"
     ]
    }
   ],
   "source": [
    "for i,b in enumerate(brains):\n",
    "    if i != 0:\n",
    "        continue\n",
    "    # using filenames of videos, load them into movie objects, creating video instance attribute\n",
    "    b.load_videos(params, normalize=False)\n",
    "    # use otsu thresholding to find binary mask, specify a results dir to save the binary mask object and plot\n",
    "    b.find_binary_mask(params, results_dir)\n",
    "\n",
    "    # use the binary mask to compute mean activity over time\n",
    "    # except here we will re-load the videos, overwriting self.video, and normalize them against the first params['n_frames_to_analyze']\n",
    "    b.load_videos(params, normalize=True)\n",
    "    b.mean_activity_within_binary_mask(params)\n",
    "    b.subtract_paraffin(puffs, params)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,b in enumerate(brains):\n",
    "    if i != 0:\n",
    "        continue\n",
    "    b.compute_max_responses(puffs, params)\n",
    "    b.compute_AUC(puffs, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the mean trace activity as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_activity = {b.name : b.mean_activity for i,b in enumerate(brains) if i == 0}\n",
    "mean_activity_df = pd.DataFrame.from_dict(mean_activity)\n",
    "mean_activity_df.to_csv(f'{results_dir}/mean_activity_within_mask.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save maxs per odor as dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samp</th>\n",
       "      <th>subpop</th>\n",
       "      <th>trial</th>\n",
       "      <th>odor</th>\n",
       "      <th>value</th>\n",
       "      <th>odor_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230913_ORL_GCaMP6f_F1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>1</td>\n",
       "      <td>hexanal4.375</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230913_ORL_GCaMP6f_F1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2</td>\n",
       "      <td>hexanal4.375</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230913_ORL_GCaMP6f_F1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>1</td>\n",
       "      <td>hexanal4.03</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230913_ORL_GCaMP6f_F1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2</td>\n",
       "      <td>hexanal4.03</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230913_ORL_GCaMP6f_F1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>1</td>\n",
       "      <td>hexanal2.825</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>230913_ORL_GCaMP6f_F1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2</td>\n",
       "      <td>hexanoic acid</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>230913_ORL_GCaMP6f_F1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>1</td>\n",
       "      <td>camphor</td>\n",
       "      <td>0.009764</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>230913_ORL_GCaMP6f_F1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2</td>\n",
       "      <td>camphor</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>230913_ORL_GCaMP6f_F1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>1</td>\n",
       "      <td>1-octen-3-ol</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>230913_ORL_GCaMP6f_F1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2</td>\n",
       "      <td>1-octen-3-ol</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     samp subpop  trial           odor     value  odor_order\n",
       "0   230913_ORL_GCaMP6f_F1    ORL      1   hexanal4.375  0.000476           0\n",
       "1   230913_ORL_GCaMP6f_F1    ORL      2   hexanal4.375  0.000475           0\n",
       "2   230913_ORL_GCaMP6f_F1    ORL      1    hexanal4.03  0.001123           1\n",
       "3   230913_ORL_GCaMP6f_F1    ORL      2    hexanal4.03  0.000477           1\n",
       "4   230913_ORL_GCaMP6f_F1    ORL      1   hexanal2.825  0.001073           2\n",
       "..                    ...    ...    ...            ...       ...         ...\n",
       "67  230913_ORL_GCaMP6f_F1    ORL      2  hexanoic acid  0.001025          33\n",
       "68  230913_ORL_GCaMP6f_F1    ORL      1        camphor  0.009764          34\n",
       "69  230913_ORL_GCaMP6f_F1    ORL      2        camphor  0.006896          34\n",
       "70  230913_ORL_GCaMP6f_F1    ORL      1   1-octen-3-ol  0.000644          35\n",
       "71  230913_ORL_GCaMP6f_F1    ORL      2   1-octen-3-ol  0.001049          35\n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_df(brains, puffs, metric):\n",
    "    df_list = []\n",
    "    for i,b in enumerate(brains):\n",
    "        if i != 0:\n",
    "            continue\n",
    "        df_tmp = pd.DataFrame.from_dict(getattr(b, metric))\n",
    "        df_tmp['samp'] = b.name\n",
    "        df_tmp['subpop'] = b.name.split('_')[1]\n",
    "        df_tmp['trial'] = df_tmp.index+1\n",
    "        df_list.append(df_tmp)\n",
    "    df = pd.concat(df_list)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = pd.melt(df, id_vars=['samp', 'subpop', 'trial'], var_name='odor', value_name='value')\n",
    "\n",
    "    odor_order = {}\n",
    "    for puff in puffs:\n",
    "        if puff.trial == 1:\n",
    "            odor_order[puff.odor_name] = puff.number\n",
    "\n",
    "    df['odor_order'] = df['odor'].map(odor_order)\n",
    "    return df\n",
    "\n",
    "peak_max_df = convert_to_df(brains, puffs, 'maxs_per_odor')\n",
    "peak_auc_df = convert_to_df(brains, puffs, 'aucs_per_odor')\n",
    "peak_max_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_activity_plot(brains, params, metric):\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(16, 4))\n",
    "\n",
    "    for i,b in enumerate(brains):\n",
    "        if i != 0:\n",
    "            continue\n",
    "\n",
    "        activity = getattr(b, metric)\n",
    "        plt.plot(activity + i*0.02, c='black')  # Offset each trace by i*3\n",
    "        # print sample name on the right\n",
    "        plt.text(len(activity)*1.02, i*0.02, b.name, color='black')\n",
    "\n",
    "    # print the names of the odors on the x-axis\n",
    "    odor_names = []\n",
    "    positions = []\n",
    "    for i,puff in enumerate(puffs):\n",
    "        odor_names.append(puff.odor_name)\n",
    "        positions.append(i*params['n_frames_to_analyze'] + params['n_frames_to_analyze']/2)\n",
    "    plt.xticks(positions, odor_names, rotation=90)\n",
    "\n",
    "    # draw vertical lines to separate odors\n",
    "    for i in range(len(puffs)):\n",
    "        plt.axvline((i+1)*params['n_frames_to_analyze'], color=\"black\", linestyle=\"--\", alpha=0.1)\n",
    "\n",
    "    plt.yticks([])\n",
    "    # supress grid lines\n",
    "    plt.grid(False)\n",
    "    sns.despine()\n",
    "\n",
    "    plt.savefig(f'{results_dir}/{metric}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "make_mean_activity_plot(brains, params, metric='mean_activity')\n",
    "make_mean_activity_plot(brains, params, metric='mean_activity_paraffin_subtracted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
