{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pixel intensity thresholding to segment the entire mosquito antennal lobe (AL)\n",
    "\n",
    "This notebook is kept tidy by modularizing the data and code into separate python files that are imported here. Data is stored in the `Brains` data class specified below, and these data are processed using function in modules in the `utils` directory.\n",
    "\n",
    "IMPORTANT: See `experiment_info.py` to specify details related to the experiment. These details are imported below\n",
    "\n",
    "If you have different experiments, simply store the information in a separate python file and change the name `experiment_info` in the cell below to correspond to the file with the information from this other experiment.\n",
    "\n",
    "**NOTES**: \n",
    "- There should be as many .tif videos as there are odors, and it is assumed that these videos are alphanumerically labeled in the same order as they appear in `odor_string`. I.e., if we sort the names of the videos, the first one should correspond to the first odor in `odor_string`.\n",
    "- For computational speed, this code should be run wherever the raw data are stored. If you mount the file system where the data are stored (e.g. PNI cluster) and run the code on your local machine, it may go very slow as the data has to transfer over the network. I currently use this notebook for interactive work, but when I'm satisfied with the results for a few samples, I export this notebook as a python script using `jupyter nbconvert --to script 01_segment_and_extract_traces.ipynb` and then execute this script as a job using SLURM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import caiman as cm\n",
    "\n",
    "results_dir = 'results_tmp'\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom modules that can be found in the parent directory of this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_info import samples, data_dir, puffs, params\n",
    "\n",
    "import utils.activity_traces as activity_traces\n",
    "import utils.video_IO as video_IO\n",
    "import utils.binary_mask as binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data directory: /mnt/cup/labs/mcbride/bjarnold/new_analysis/data/Mar_22_2024/1_RegisteredBrains\n",
      "Number of samples: 15\n",
      "Number of odors: 72\n",
      "x,y,z dimensions: 128 128 24\n",
      "Number of frames to analyze: 112\n",
      "Number of initial frames for df/f normalization: 20\n"
     ]
    }
   ],
   "source": [
    "print(f'data directory: {data_dir}')\n",
    "print(f'Number of samples: {len(samples)}')\n",
    "num_odors = len(puffs)\n",
    "\n",
    "print(f'Number of odors: {num_odors}')\n",
    "print(f'x,y,z dimensions:', params['x_dim'], params['y_dim'], params['z_dim'])\n",
    "print(f'Number of frames to analyze:', params['n_frames_to_analyze'])\n",
    "print(f'Number of initial frames for df/f normalization:', params['background_frames'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the `Brain` data class that will store organized information for each sample\n",
    "\n",
    "When creating the data class, `slots=True` means no new attributes can be added to the class. Only attributes `name` and `vid_fnames` need to be specified when initializing each instance (see below). Other attributes will be assigned values as the data are processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True)\n",
    "class Brain:\n",
    "\n",
    "    name: str   # name of the sample\n",
    "    vid_fnames: list # the file paths of all the individual videos\n",
    "\n",
    "    # the following attributes, initialized here, are computed using vid_fnames\n",
    "    video: cm.base.movies.movie = None # the full video, a concatenation of all individual videos\n",
    "    \n",
    "    binary_mask: np.array = None # 3D outline of the antennal lobe, region in video of higher pixel intensities according to otsu thresholding\n",
    "    binary_mask_frac: float = None # the fraction of pixels contained within binary_mask, compared to the entire 3d volume\n",
    "    \n",
    "    mean_activity: np.array = None # the mean pixel intensity wtihin binary mask, over time; this is df_f if videos have been normalized against background activity\n",
    "    maxs_per_odor: defaultdict(list) = None # a dictionary where keys are names of odors, values are lists of size 2, one for each trial in which the odor was administered\n",
    "    argmaxs_per_odor: defaultdict(list) = None # a dictionary where keys are names of odors, values are lists of size 2, one for each trial in which the odor was administered\n",
    "    aucs_per_odor: defaultdict(list) = None # same as maxs_per_odor, except calculating the area under the curve\n",
    "    \n",
    "    mean_activity_paraffin_subtracted: np.array = None # same as mean_activity except the signal of the paraffin odor has been subtracted\n",
    "    maxs_per_odor_paraffin_subtracted: defaultdict(list) = None # same as maxs_per_odor except the signal of the paraffin odor has been subtracted\n",
    "    argmaxs_per_odor_paraffin_subtracted: defaultdict(list) = None\n",
    "    aucs_per_odor_paraffin_subtracted: defaultdict(list) = None # same as aucs_per_odor, except calculating the area under the curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will store all information within a list called `brains`, that will contain one element per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230913_ORL_GCaMP6f_F1: 72 videos\n",
      "230913_ORL_GCaMP6f_F2: 72 videos\n",
      "230914_ORL_GCaMP6f_F1: 72 videos\n",
      "230914_ORL_GCaMP6f_F2: 72 videos\n",
      "230915_ORL_GCaMP6f_F1: 72 videos\n",
      "230913_U52_GCaMP6f_F2: 72 videos\n",
      "230913_U52_GCaMP6f_F3: 72 videos\n",
      "230914_U52_GCaMP6f_F1: 72 videos\n",
      "230914_U52_GCaMP6f_F2: 72 videos\n",
      "230915_U52_GCaMP6f_F2: 72 videos\n",
      "230913_FCV_GCaMP6f_F1: 72 videos\n",
      "230914_FCV_GCaMP6f_F1: 72 videos\n",
      "230914_FCV_GCaMP6f_F2: 72 videos\n",
      "230914_FCV_GCaMP6f_F3: 72 videos\n",
      "230915_FCV_GCaMP6f_F1: 72 videos\n"
     ]
    }
   ],
   "source": [
    "brains = []\n",
    "\n",
    "for samp_name in samples:\n",
    "    # get list of video file names for this sample\n",
    "    v = glob.glob(f\"{data_dir}/{samp_name}/*.registered.tif\")\n",
    "    v = sorted(v)\n",
    "    num_vids = len(v)\n",
    "    assert num_vids == len(puffs), f\"I found {num_vids} videos for sample {samp_name}, but there are {len(puffs)} odors. The number of videos and odors should be equivalent.\"\n",
    "\n",
    "    # initialize a Brain object for this sample\n",
    "    brain = Brain(samp_name, v)\n",
    "    brains.append(brain)\n",
    "\n",
    "for b in brains:\n",
    "    print(f'{b.name}: {len(b.vid_fnames)} videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is where most of the work is done.\n",
    "For each sample, we pass the attributes to modules in the `utils` directory which has functions that we will reuse in other analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393216,) (8064, 393216)\n",
      "(393216,) (8064, 393216)\n",
      "(393216,) (8064, 393216)\n",
      "(393216,) (8064, 393216)\n",
      "(393216,) (8064, 393216)\n",
      "(393216,) (8064, 393216)\n",
      "(393216,) (8064, 393216)\n",
      "(393216,) (8064, 393216)\n",
      "(393216,) (8064, 393216)\n",
      "(393216,) (8064, 393216)\n"
     ]
    }
   ],
   "source": [
    "for i,b in enumerate(brains):\n",
    "\n",
    "    # using filenames of videos, load them into movie objects, creating video instance attribute\n",
    "    b.video = video_IO.load_videos(b.vid_fnames, params, normalize=False)\n",
    "\n",
    "    # use otsu thresholding to find binary mask\n",
    "    b.binary_mask, b.binary_mask_frac = binary_mask.find_binary_mask(b.video, params)\n",
    "\n",
    "    # save the binary mask object and plot\n",
    "    binary_mask.save_and_plot_binary_mask(b.name, b.binary_mask, params, results_dir)\n",
    "\n",
    "    # use the binary mask to compute mean activity over time\n",
    "    # except here we will re-load the videos, overwriting video attribute, and normalize each video using spontaneous activity during first params['background_frames']\n",
    "    b.video = video_IO.load_videos(b.vid_fnames, params, normalize=True)\n",
    "    b.mean_activity = binary_mask.mean_activity_within_binary_mask(b.video, b.binary_mask, params)\n",
    "    \n",
    "    # using these mean activities, compute max activity and AUC for each odor in the series\n",
    "    b.maxs_per_odor, b.argmaxs_per_odor = activity_traces.max_activity_per_odor(b.mean_activity, puffs, params)\n",
    "    b.aucs_per_odor = activity_traces.activity_auc_per_odor(b.mean_activity, puffs, params)\n",
    "    \n",
    "    # repeat the above steps, but subtract the paraffin odor from the mean activity\n",
    "    b.mean_activity_paraffin_subtracted = activity_traces.subtract_paraffin_response(b.mean_activity, puffs, params)    \n",
    "    b.maxs_per_odor_paraffin_subtracted, b.argmaxs_per_odor_paraffin_subtracted = activity_traces.max_activity_per_odor(b.mean_activity_paraffin_subtracted, puffs, params)\n",
    "    b.aucs_per_odor_paraffin_subtracted = activity_traces.activity_auc_per_odor(b.mean_activity_paraffin_subtracted, puffs, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the mean trace activity as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_activity = {b.name : b.mean_activity for i,b in enumerate(brains)}\n",
    "mean_activity_df = pd.DataFrame.from_dict(mean_activity)\n",
    "mean_activity_df.to_csv(f'{results_dir}/mean_activity_within_mask.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert maxs per odor to a Pandas DataFrame and then save as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_df(brains, puffs, metric):\n",
    "    df_list = []\n",
    "    for i,b in enumerate(brains):\n",
    "        df_tmp = pd.DataFrame.from_dict(getattr(b, metric))\n",
    "        df_tmp['samp'] = b.name\n",
    "        df_tmp['subpop'] = b.name.split('_')[1]\n",
    "        df_tmp['trial'] = df_tmp.index+1\n",
    "        df_list.append(df_tmp)\n",
    "    df = pd.concat(df_list)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = pd.melt(df, id_vars=['samp', 'subpop', 'trial'], var_name='odor', value_name='value')\n",
    "\n",
    "    odor_order = {}\n",
    "    for puff in puffs:\n",
    "        if puff.trial == 1:\n",
    "            odor_order[puff.odor_name] = puff.number\n",
    "\n",
    "    df['odor_order'] = df['odor'].map(odor_order)\n",
    "    return df\n",
    "\n",
    "peak_max_df = convert_to_df(brains, puffs, 'maxs_per_odor')\n",
    "peak_auc_df = convert_to_df(brains, puffs, 'aucs_per_odor')\n",
    "peak_max_df.to_csv(f'{results_dir}/peak_max.csv', index=False)\n",
    "peak_auc_df.to_csv(f'{results_dir}/peak_auc.csv', index=False)\n",
    "\n",
    "# repeat for paraffin subtracted\n",
    "peak_max_df = convert_to_df(brains, puffs, 'maxs_per_odor_paraffin_subtracted')\n",
    "peak_auc_df = convert_to_df(brains, puffs, 'aucs_per_odor_paraffin_subtracted')\n",
    "peak_max_df.to_csv(f'{results_dir}/peak_max_paraffin_subtracted.csv', index=False)\n",
    "peak_auc_df.to_csv(f'{results_dir}/peak_auc_paraffin_subtracted.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a pretty plot of all the activity traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_activity_plot(brains, params, metric):\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(16, 4))\n",
    "\n",
    "    for i,b in enumerate(brains):\n",
    "\n",
    "        activity = getattr(b, metric)\n",
    "        plt.plot(activity + i*0.02, c='black')  # Offset each trace by i*3\n",
    "        # print sample name on the right\n",
    "        plt.text(len(activity)*1.02, i*0.02, b.name, color='black')\n",
    "\n",
    "    # print the names of the odors on the x-axis\n",
    "    odor_names = []\n",
    "    positions = []\n",
    "    for i,puff in enumerate(puffs):\n",
    "        odor_names.append(puff.odor_name)\n",
    "        positions.append(i*params['n_frames_to_analyze'] + params['n_frames_to_analyze']/2)\n",
    "    plt.xticks(positions, odor_names, rotation=90)\n",
    "\n",
    "    # draw vertical lines to separate odors\n",
    "    for i in range(len(puffs)):\n",
    "        plt.axvline((i+1)*params['n_frames_to_analyze'], color=\"black\", linestyle=\"--\", alpha=0.1)\n",
    "\n",
    "    plt.yticks([])\n",
    "    # supress grid lines\n",
    "    plt.grid(False)\n",
    "    sns.despine()\n",
    "\n",
    "    plt.savefig(f'{results_dir}/{metric}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "make_mean_activity_plot(brains, params, metric='mean_activity')\n",
    "make_mean_activity_plot(brains, params, metric='mean_activity_paraffin_subtracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argmaxs_per_odor: <class 'collections.defaultdict'>\n",
      "argmaxs_per_odor_paraffin_subtracted: <class 'collections.defaultdict'>\n",
      "aucs_per_odor: <class 'collections.defaultdict'>\n",
      "aucs_per_odor_paraffin_subtracted: <class 'collections.defaultdict'>\n",
      "binary_mask: <class 'numpy.ndarray'>\n",
      "binary_mask_frac: <class 'numpy.float64'>\n",
      "maxs_per_odor: <class 'collections.defaultdict'>\n",
      "maxs_per_odor_paraffin_subtracted: <class 'collections.defaultdict'>\n",
      "mean_activity: <class 'numpy.ndarray'>\n",
      "mean_activity_paraffin_subtracted: <class 'numpy.ndarray'>\n",
      "name: <class 'str'>\n",
      "vid_fnames: <class 'list'>\n",
      "video: <class 'caiman.base.movies.movie'>\n"
     ]
    }
   ],
   "source": [
    "# iterate through attributes of brains[0] and print the type\n",
    "for attr in dir(brains[0]):\n",
    "    if not attr.startswith('__'):\n",
    "        print(f'{attr}: {type(getattr(brains[0], attr))}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
